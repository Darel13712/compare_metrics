{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE:\n",
    "    def __init__(self):\n",
    "        self.user_enc = LabelEncoder()\n",
    "        self.item_enc = LabelEncoder()\n",
    "\n",
    "    def _get_users_and_items(self, df):\n",
    "        users = self.user_enc.fit_transform(df.loc[:, 'user_id'])\n",
    "        items = self.item_enc.fit_transform(df.loc[:, 'item_id'])\n",
    "        return users, items\n",
    "\n",
    "    def fit(self, df, lambda_: float = 0.5, implicit=True):\n",
    "        \"\"\"\n",
    "        df: pandas.DataFrame with columns user_id, item_id and (rating)\n",
    "        lambda_: l2-regularization term\n",
    "        implicit: if True, ratings are ignored and taken as 1, else normalized ratings are used\n",
    "        \"\"\"\n",
    "        users, items = self._get_users_and_items(df)\n",
    "        values = np.ones(df.shape[0]) if implicit else df['rating'].to_numpy() / df['rating'].max()\n",
    "\n",
    "        X = csr_matrix((values, (users, items)))\n",
    "        self.X = X\n",
    "\n",
    "        G = X.T.dot(X).toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = np.linalg.inv(G)\n",
    "        B = P / (-np.diag(P))\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.B = B\n",
    "        self.pred = X.dot(B)\n",
    "\n",
    "    def predict(self, train, users, items, k):\n",
    "        df = pd.DataFrame()\n",
    "        items = self.item_enc.transform(items)\n",
    "        dd = train.loc[train.user_id.isin(users)]\n",
    "        dd['ci'] = self.item_enc.transform(dd.item_id)\n",
    "        dd['cu'] = self.user_enc.transform(dd.user_id)\n",
    "        g = dd.groupby('user_id')\n",
    "        for user, group in tqdm(g):\n",
    "            watched = set(group['ci'])\n",
    "            candidates = [item for item in items if item not in watched]\n",
    "            u = group['cu'].iloc[0]\n",
    "            pred = np.take(self.pred[u, :], candidates)\n",
    "            res = np.argpartition(pred, 0) #res = np.argpartition(pred, -k)[-k:]\n",
    "            r = pd.DataFrame({\n",
    "                \"user_id\": [user] * len(res),\n",
    "                \"item_id\": np.take(candidates, res),\n",
    "                \"score\": np.take(pred, res)\n",
    "            }).sort_values('score', ascending=False)\n",
    "            df = df.append(r, ignore_index=True)\n",
    "        df['item_id'] = self.item_enc.inverse_transform(df['item_id'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EASE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.9 s, sys: 3.27 s, total: 52.2 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = len(train.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, N, i):\n",
    "    all_users = sorted(list(test.user_id.unique()))\n",
    "    \n",
    "    lower = max(\n",
    "            0,\n",
    "            int(len(all_users) * float(i) / N)\n",
    "        )\n",
    "    upper = min(\n",
    "            int(len(all_users) * float(i+1) / N), \n",
    "            len(all_users)\n",
    "        )\n",
    "    \n",
    "    users = all_users[lower:upper]\n",
    "    \n",
    "    model.predict(train, users, train.item_id.unique(), num_items).to_csv('pred_full_{}.csv'.format(i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexxl/recsys2021/venv/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "  9%|▉         | 8/85 [00:00<00:00, 77.69it/s]/Users/alexxl/recsys2021/venv/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      " 41%|████      | 35/85 [00:00<00:00, 65.09it/s]"
     ]
    }
   ],
   "source": [
    "N = 32\n",
    "with Parallel(n_jobs=N) as p:\n",
    "    p([delayed(predict)(model, N, i) for i in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(x) for x in os.listdir() if 'pred_full_' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preds_full.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
